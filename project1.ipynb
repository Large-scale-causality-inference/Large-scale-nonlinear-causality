{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "project1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ali-vosoughi/Large-scale-nonlinear-causality/blob/main/project1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOCGqdm1wibB"
      },
      "source": [
        "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
        "\n",
        "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
      ],
      "id": "VOCGqdm1wibB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMo1LctBwibF"
      },
      "source": [
        "NAME = \"\""
      ],
      "id": "GMo1LctBwibF",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD8XpqENwibG"
      },
      "source": [
        "---"
      ],
      "id": "vD8XpqENwibG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "2e38e8cfa6db3f59d8bffd6e8d6b2d18",
          "grade": false,
          "grade_id": "cell-61902e9b43fe1aa6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "e1kDfF8awibG"
      },
      "source": [
        "# Implementation of deep neural network\n",
        "\n",
        "You will use the knowledge you'd learned in the class to build a 3 layer feed forward neural network, and apply it to a ten-class image classification problem. Hopefully, you will learn how to implement backpropagation and optimization.\n",
        "\n",
        "Let's get started!"
      ],
      "id": "e1kDfF8awibG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "50c9d0dbe6381074fc313d01b19ce31a",
          "grade": false,
          "grade_id": "cell-6fde9518151c06f0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "FSOH0bJtwibH"
      },
      "source": [
        "## 1. Package\n",
        "\n",
        "Let's first import all the packages that you will need.\n",
        "\n",
        "- **torch, torch.nn, torch.nn.functional** are the fundamental modules in pytorch library, supporting Python programs that facilitates building deep learning projects.\n",
        "- **torchvision** is a library for Computer Vision that goes hand in hand with PyTorch\n",
        "- **numpy** is the fundamental package for scientific computing with Python programs.\n",
        "- **matplotlib** is a library to plot graphs and images in Python.\n",
        "- **math, random** are the standard modules in Python."
      ],
      "id": "FSOH0bJtwibH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bbc346bdb6a037e971378bba3ca48310",
          "grade": true,
          "grade_id": "cell-95d842eb9dc9d856",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "DE1DFpQ4wibH",
        "outputId": "392a3339-f601-4ebe-dfb1-be25bffa347b"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from project1_utils import *\n",
        "\n",
        "print(\"Import packages successfully!\")"
      ],
      "id": "DE1DFpQ4wibH",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6d6f001b72aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mproject1_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Import packages successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'project1_utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "879bf010acbd9618138b556ce794f3dd",
          "grade": false,
          "grade_id": "cell-b528308013dd165f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "HI7i-NoAwibI"
      },
      "source": [
        "A helper function is provided:\n",
        "\n",
        "```python\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    TODO: Use random seed to ensure that results are reproducible.\n",
        "    \"\"\"\n",
        "```"
      ],
      "id": "HI7i-NoAwibI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0233fdb270c744b0966fad9b95fd06fa",
          "grade": true,
          "grade_id": "cell-017397b54ab692ac",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "aAUYHwEuwibJ"
      },
      "source": [
        "seed = 1\n",
        "set_seed(seed)"
      ],
      "id": "aAUYHwEuwibJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "43ca57a2b2923b23634d6e3cb069efda",
          "grade": false,
          "grade_id": "cell-ff95df93105ccae5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "q5itNIGfwibK"
      },
      "source": [
        "## 2. Dataset\n",
        "\n",
        "You will use the \"cat vs. dog\" dataset for this assignment.\n",
        "\n",
        "Let's load the dataset first using pytorch dataset and loader modules."
      ],
      "id": "q5itNIGfwibK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "100a54057162a97f6b36bb850b01c1a1",
          "grade": true,
          "grade_id": "cell-f798e30fc96e134e",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "IEboFSx0wibK"
      },
      "source": [
        "# the number of images in a batch\n",
        "batch_size = 4\n",
        "\n",
        "# load dataset\n",
        "trainset = dataset(path='/u/cs298/project1/dataset/trainset.h5')\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testset = dataset(path='/u/cs298/project1/dataset/testset.h5')\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# name of classes\n",
        "classes = ('cat', 'dog')\n",
        "\n",
        "print (\"Number of training examples: \" + str(trainset.length))\n",
        "print (\"Number of testing examples: \" + str(testset.length))"
      ],
      "id": "IEboFSx0wibK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8763848939a09c6fc8b23b09a309b353",
          "grade": false,
          "grade_id": "cell-7081b78dc3a8d0ca",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "n75wNftKwibL"
      },
      "source": [
        "Let's visualize some examples in the dataset, a helper function to show images is provided as below:\n",
        "\n",
        "```python\n",
        "def imshow(images):\n",
        "    \"\"\"\n",
        "    TODO: Display the input images in a plot\n",
        "    \"\"\"\n",
        "```"
      ],
      "id": "n75wNftKwibL"
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "92726db6ebd60af5d3409eae9f9f10a1",
          "grade": true,
          "grade_id": "cell-1ad90426f0c574d0",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8xUEtKFlwibL"
      },
      "source": [
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "num_toshow = 4\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images[:num_toshow]))\n",
        "\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(num_toshow)))"
      ],
      "id": "8xUEtKFlwibL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4da8d8983e0c7ae28b037745ced5fc16",
          "grade": false,
          "grade_id": "cell-d65c5901e6efc6e1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "fa_Du-t5wibM"
      },
      "source": [
        "## 3. Build your feedforward neural network.\n",
        "\n",
        "In this cell, you will be required to build a **3-layer multilayer perceptron (MLP)** to classify images into different categories.\n",
        "\n",
        "As we know from the class, **each layer** of a MLP can be denoted as the following mathematical operation:\n",
        "\n",
        "$$z = W^T x + b$$ $$a = \\sigma(z)$$\n",
        "\n",
        "Here, $W, b$ denote the weights and biases, and $a, \\sigma$ denote activation and activation function, respectively.\n",
        "**The function is parameterized by $W, b$ as well as the choice of $\\sigma(\\cdot)$**.\n",
        "\n",
        "Note that it is valid for $\\sigma(\\cdot)$ to be the identity function, or $z = \\sigma(z)$.\n",
        "\n",
        "----\n",
        "\n",
        "**Question 1 (6 points):** Now, let's implement functions at the layer level to do the following:\n",
        "\n",
        "Hint: To implement $W^Tx+b$ in PyTorch, one way is to write it as `x.mm(W) + b`."
      ],
      "id": "fa_Du-t5wibM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1b30b45baac898ee7729ebecc0ae7ed5",
          "grade": false,
          "grade_id": "cell-aee10b8c60cb444f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1i6NXEdrwibM"
      },
      "source": [
        "1. Given the desired input, output dimensions, generate the parameters $W, b$. (2 points)"
      ],
      "id": "1i6NXEdrwibM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1a3bbf7c2e3c4abb12b354bd026130a8",
          "grade": true,
          "grade_id": "cell-24644c097079f609",
          "locked": false,
          "points": 2,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ykE7koAdwibM"
      },
      "source": [
        "def get_layer_params(input_dim: int, output_dim: int, batch_size: int, sigma):\n",
        "    \"\"\"\n",
        "    Input: \n",
        "        input_dim: number of length in the input\n",
        "        output_dim: number of length produced by the layer\n",
        "        batch_size: number of examples from the training dataset used in the estimate of gradients, batch_size \\\n",
        "            controls the accuracy of the estimate of the error gradients when training neural networks\n",
        "        sigma: activation function\n",
        "    Output: \n",
        "        a dictionary of generated parameters\n",
        "    \"\"\"\n",
        "    # TODO:\n",
        "    w = None\n",
        "    b = None\n",
        "    \n",
        "    # generate the parameters\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "    \n",
        "    return {'w': w,\n",
        "            'b': b,\n",
        "            'sigma': sigma}\n",
        "    "
      ],
      "id": "ykE7koAdwibM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b833095878705edf44391dab71274a85",
          "grade": false,
          "grade_id": "cell-37d560a619728dd8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Gx-UDGxKwibN"
      },
      "source": [
        "2. Given the layer parameters $W, b$ and the choice of $\\sigma(\\cdot)$, compute the output for layer input $X$. (4 points)"
      ],
      "id": "Gx-UDGxKwibN"
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a4734233982be0cde5559ff7e141d21c",
          "grade": true,
          "grade_id": "cell-3b88b8f84dd5393b",
          "locked": false,
          "points": 4,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "riXx-wHPwibN"
      },
      "source": [
        "def layer_forward_computation(params, x):\n",
        "    \"\"\"\n",
        "    Input: \n",
        "        params: parameters of each layer\n",
        "        x: the input to the layer\n",
        "    Output: \n",
        "        the output after and before activation\n",
        "    \"\"\"\n",
        "    # unpack params\n",
        "    w, b, sigma = params['w'], params['b'], params['sigma']\n",
        "    \n",
        "    a = None\n",
        "    \n",
        "    # compute the output for layer\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "    \n",
        "    return a, z"
      ],
      "id": "riXx-wHPwibN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a52483e87583a52cc224a733a431685b",
          "grade": false,
          "grade_id": "cell-aadf7e24fd04c923",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "BMqzApFawibN"
      },
      "source": [
        "---\n",
        "\n",
        "Back to building our 3-layer MLP for classification. If you have implemented the functions above correctly,\n",
        "now the processing of putting everything together will be very easy.\n",
        "\n",
        "Just like other parts of your programming experience,\n",
        "knowing how to efficiently abstract and modularize components of your program will be critical in deep learning.\n",
        "\n",
        "**Architecture Requirement**:\n",
        "\n",
        "We now describe in details how our 3-layer MLP should be built in PyTorch.\n",
        "\n",
        "1. In the dataset, the size of input image is a tensor $ X \\in \\mathbb{R}^{B \\times 32 \\times 32 \\times 3}$, where $B$ denotes the batch size.\n",
        "2. Flatten the image tensor to a vector $X_{flattened} \\in \\mathbb{R}^{B \\times 3072}$.\n",
        "3. We now begin describing the specific architecture of the model, although this is not the only design choice, and feel free to change the hidden dimensions of the parameters\n",
        "4. Layer1: set your parameters so the input is projected from $\\mathbb{R}^{B \\times 3072}$ to $\\mathbb{R}^{B \\times 240}$, use ReLU as your activation function\n",
        "5. Layer2: set your parameters so the input is projected from $\\mathbb{R}^{B \\times 240}$ to $\\mathbb{R}^{B \\times 84}$, use ReLU as your activation function\n",
        "6. Layer3: set your parameters so the input is projected from $\\mathbb{R}^{B \\times 84}$ to $\\mathbb{R}^{B \\times 10}$, use identity function as your activation function\n",
        "\n",
        "---\n",
        "\n",
        "**Question 2 (4 points):** Let's build the 3-layer MLP using the pre-defined function **get_layer_params( )**."
      ],
      "id": "BMqzApFawibN"
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c26c8958026f04c5bd65809803ab9b89",
          "grade": true,
          "grade_id": "cell-8611eb15d3df224c",
          "locked": false,
          "points": 4,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2Vb1G2liwibN"
      },
      "source": [
        "\"\"\" TODO: define your layer parameters here \"\"\"\n",
        "layer1_params: dict = dict()\n",
        "layer2_params: dict = dict()\n",
        "layer3_params: dict = dict()\n",
        "\n",
        "# build your network\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ],
      "id": "2Vb1G2liwibN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "36a870ef2c60c106e6a563da218eeddb",
          "grade": false,
          "grade_id": "cell-43f73655c5164eda",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "g9Tji9W_wibO"
      },
      "source": [
        "---\n",
        "\n",
        "Now your whole network function is defined as below:"
      ],
      "id": "g9Tji9W_wibO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b94415e294cf4a11508f801a99994c99",
          "grade": true,
          "grade_id": "cell-46335680e32c5b0f",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hiIKDbvEwibO"
      },
      "source": [
        "def net(x, params):\n",
        "    assert len(params) == 3\n",
        "    layer1_params, layer2_params, layer3_params = params\n",
        "    \n",
        "    l1_out = layer_forward_computation(layer1_params, x)\n",
        "    l2_out = layer_forward_computation(layer2_params, l1_out[0])\n",
        "    l3_out = layer_forward_computation(layer3_params, l2_out[0])\n",
        "    return l1_out, l2_out, l3_out"
      ],
      "id": "hiIKDbvEwibO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "242165cd51d4514ebd7c0031d9ba850d",
          "grade": false,
          "grade_id": "cell-e014df9a9afed7e9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "fVLXt3bnwibO"
      },
      "source": [
        "## 4. Backpropagation and optimization"
      ],
      "id": "fVLXt3bnwibO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "2081b40069e5a1b03eeb8fef97ed8357",
          "grade": false,
          "grade_id": "cell-bece3191f484976f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "DfybALkswibO"
      },
      "source": [
        "**Question 3 (6 points):** After computing the forward pass, you now need to compute gradients with respect to all Tensors with `requires_grad=True`, e.g., parameters of layer1. These graidents will be used to update parameters via gradient descent. \n",
        "\n",
        "**Requirements:** You will need to complete the function **default_backprop( )** and **zero_grad( )** and implement them in the training process. \n",
        "\n",
        "Hint1: You can use `autograd` in PyTorch to compute gradients.\n",
        "\n",
        "Hint2: You should manually zero the gradients after updating weights.\n",
        "\n",
        "---"
      ],
      "id": "DfybALkswibO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e757b8df420fae4cb0c7a5ea3393fb27",
          "grade": false,
          "grade_id": "cell-25bcd84dc444c485",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "gH4pnwKuwibO"
      },
      "source": [
        "Gradient descent is a way to minimize the final objective function (loss) parameterized by a model's parameter $\\theta$ by updating the parameters in the opposite direction of the gradient $\\nabla_\\theta J(\\theta)$ w.r.t to the parameters. The learning rate $\\lambda$ determines the size of the steps you take to reach a (local) minimum.\n",
        "\n",
        "Now following the equation to update parameters for each layer in your network.\n",
        "\n",
        "$$\\large \\theta = \\theta - \\lambda\\cdot\\nabla_\\theta J(\\theta)$$\n",
        "\n",
        "---\n",
        "\n",
        "**Question 4 (3 points):** You will use the computed gradients to update the parameters for feedforward network. For this step, function **update_params( )** should be completed.\n",
        "\n",
        "Hint: To get grident and operate it in PyTorch, you can call `x.grad`."
      ],
      "id": "gH4pnwKuwibO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "225d0fcd4c1c8cdaf594bd2bcdf862ae",
          "grade": true,
          "grade_id": "cell-3ace7576abd4e7f8",
          "locked": false,
          "points": 3,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "fQyJ7vfHwibO"
      },
      "source": [
        "def update_params(params, learning_rate):\n",
        "    #TODO: update the parameters of each layer\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "id": "fQyJ7vfHwibO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0b32d4c6846f69b5d5ae39ad0cafbbe8",
          "grade": true,
          "grade_id": "cell-e276c24353feed3b",
          "locked": false,
          "points": 6,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KRYBhAUmwibP"
      },
      "source": [
        "\"\"\"Default Backprop Helpers\"\"\"\n",
        "\n",
        "def zero_grad(params):\n",
        "    #TODO: set the gradients with respect to parameters as zero\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "    \n",
        "def default_backprop(loss, params, learning_rate):\n",
        "    \"\"\"\n",
        "    Input: \n",
        "        loss: the objective funtion that can be used to compute gradients\n",
        "        params: parameters of each layer\n",
        "        learning_rate: the size of steps when updating parameters\n",
        "    \"\"\"    \n",
        "    #TODO: compute gradients -> update parameters -> clean graidents\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "id": "KRYBhAUmwibP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5ebbecc7a4c3ae5b7b670222aacf3729",
          "grade": false,
          "grade_id": "cell-54f264706094e49e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "tN4CXYxcwibP"
      },
      "source": [
        "---\n",
        "\n",
        "## 5. Training loop\n",
        "\n",
        "You will use a standard objective function **Binary Cross-Entropy Loss** for binary classification tasks. The detail is given as follows:\n",
        "\n",
        "$$\\large L = -\\frac{1}{N}\\sum_{i=1}^{N}( y_i \\cdot \\log(p(y_i))+(1-y_i)\\log(1-p(y_i)))$$\n",
        "\n",
        "where $y$ is the label (1 for dog and 0 for cat in our case) and $p(y)$ is the predicted probability, here $N$ equals to the batch_size.\n",
        "\n",
        "\n",
        "A initialization function is provided to help your network converge faster.\n",
        "\n",
        "```python\n",
        "def init_params(params):\n",
        "    \"\"\"\n",
        "    TODO: Initialize the parameters of each layer\n",
        "    \"\"\"\n",
        "```"
      ],
      "id": "tN4CXYxcwibP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1b9465c81b09e10d7980c05dd2bc47fc",
          "grade": true,
          "grade_id": "cell-e6824e4b20c49f4a",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "jZgVF4sCwibP"
      },
      "source": [
        "# define the learning rate here\n",
        "learning_rate = 0.001\n",
        "n_epochs = 2 # how many epochs to run\n",
        "\n",
        "# define loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "params = [layer1_params, layer2_params, layer3_params]\n",
        "\n",
        "# initialize network parameters\n",
        "init_params(params)\n",
        "    \n",
        "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Forward \n",
        "        x = torch.flatten(inputs, 1)  # flatten all dimensions except batch\n",
        "        outputs = net(x, params)\n",
        "        \n",
        "        # Compute the loss using the final output\n",
        "        final_out = outputs[-1][0]\n",
        "        loss = criterion(final_out, labels)\n",
        "\n",
        "        # Backpropagation\n",
        "        default_backprop(loss, params, learning_rate)\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 400 == 399:  # print every 2000 mini-batches\n",
        "            print('[Epoch %d, Step %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 400))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "id": "jZgVF4sCwibP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "013d59c696855d6bc7354ec2cba558af",
          "grade": false,
          "grade_id": "cell-2a7f9c550151464e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "n5H1v3RCwibP"
      },
      "source": [
        "## 6. Testing"
      ],
      "id": "n5H1v3RCwibP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b42f43ff83f9ec344b7c70f6e7669f7b",
          "grade": true,
          "grade_id": "cell-a5ef30cda9f342ab",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7bxhbyzNwibP"
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "x = torch.flatten(images, 1)\n",
        "outputs = net(x, params)\n",
        "final_out = outputs[-1][0]\n",
        "_, predicted = torch.max(final_out, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ],
      "id": "7bxhbyzNwibP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8d4f6fb520d1dc5c224fd798666abdbf",
          "grade": false,
          "grade_id": "cell-9d4eb6e5d234c194",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "dqvMhiDywibQ"
      },
      "source": [
        "**Task (1 point)**: Now testing with your trained model!"
      ],
      "id": "dqvMhiDywibQ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "841b0260a7c89fba36b1eb3f3a8352a5",
          "grade": true,
          "grade_id": "cell-ab0a206ec87856f5",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1G8N71k8wibQ"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# since you're not training, you don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # calculate outputs by running images through the network\n",
        "        x = torch.flatten(images, 1)\n",
        "        outputs = net(x, params)\n",
        "        final_out = outputs[-1][0]\n",
        "\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(final_out.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 2000 test images: %d %%' % (\n",
        "        100 * correct / total))"
      ],
      "id": "1G8N71k8wibQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "53bbb842ddc006c1d67da5f591246d3d",
          "grade": true,
          "grade_id": "cell-77cad235a42d68f5",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "tePxnDUnwibQ"
      },
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        x = torch.flatten(images, 1)\n",
        "        outputs = net(x, params)\n",
        "        final_out = outputs[-1][0]\n",
        "        _, predictions = torch.max(final_out, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
        "                                                         accuracy))"
      ],
      "id": "tePxnDUnwibQ",
      "execution_count": null,
      "outputs": []
    }
  ]
}